{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width :100%;\">\n",
    "    <td style=\"width : 7.5%;\">\n",
    "        <img style=\"float: left;\n",
    "                width: 75px;\"\n",
    "         src=\"https://upload.wikimedia.org/wikipedia/fr/d/d9/Logo_T%C3%A9l%C3%A9com_ParisTech.svg\" />\n",
    "    </td>\n",
    "    <td style=\"width : 15%;\">\n",
    "        TELECOM PARIS<br />2021/2022<br /><br /> MDI720<br />Mme Anne Sabourin\n",
    "    </td>\n",
    "    <td>\n",
    "        <h1><center>STATISTIQUES<br /><br />TP2 : Régression Linéaire</center></h1>\n",
    "    </td>\n",
    "    <td style=\"width : 12.5%;\">\n",
    "        Victor LEDEZ <br />Date TP : 2021/10/29<br /><br /> Date CR : 2021/11/10<br /> Version : 1\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devez déposer votre fichier, sous format nomdefamille.ipynb, sur le site ecampus avant le 10/11, 23h59 sur ecampus dans l’espace de rendu dédié. Pour que la correction par les pairs soit possible, aucun retard ne sera toléré (en l’absence de rendu à la date limite la note attribuée sera zéro). La correction par les pairs se fera selon les mêmes modalités qu’au premier TP noté. Ne tenez pas compte du barême pour la correction, notez toujours sur 2 points chaque question, la pondération s’effectue automatiquement dans la feuille excel. Date limite de rendu de la correction : le 21/11 23h59.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "> Nous travaillons sur la base de données diabetes de python. La base initiale comporte n “ 442 patients et p “ 10 covariables. La variable Y à expliquer est un score correspondant à l’évolution de la maladie. Pour s’amuser, un robot malicieux a contaminé le jeu de données en y ajoutant 150 variables explicatives inappropriées. Ensuite, non-content d’avoir déjà perverti notre jeu de données, il a volon\u0002tairement mélangé les variables entre elles de façon aléatoire. Bien entendu le robot a ensuite pris soin d’effacer toute trace de son acte crapuleux si bien que nous ne connaissons pas les variables pertinentes.La nouvelle base de données notée X comporte n “ 442 patients et p “ 160 covariables. Saurez-vous déjouer les plans de ce robot farceur et retrouver les variables pertinentes ?\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 1\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Importer la base de données data_contamine.csv disponible depuis le lien https://github.com/anassag/TP-reduction-dimension/blob/main/data_contamine.csv. La dernière colonne est la variable à expliquer. Les autres colonnes sont les variables explicatives. Vérifiez le nombre de va\u0002riables explicatives et le nombre d’observations. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.237733528583032705e-01</th>\n",
       "      <th>2.407005121478057230e+00</th>\n",
       "      <th>-5.360732885543344484e-01</th>\n",
       "      <th>-1.336625915483726335e+00</th>\n",
       "      <th>-9.794715446704517492e-02</th>\n",
       "      <th>1.549540399810333424e+00</th>\n",
       "      <th>1.590890177396816707e+00</th>\n",
       "      <th>1.190101277089628207e+00</th>\n",
       "      <th>-1.181935530900874776e+00</th>\n",
       "      <th>2.731035665376587929e+00</th>\n",
       "      <th>...</th>\n",
       "      <th>-1.157572374481870670e+00</th>\n",
       "      <th>-3.169548928408494337e-01</th>\n",
       "      <th>-1.041194344071040945e+00</th>\n",
       "      <th>-9.297458111228392719e-01</th>\n",
       "      <th>-1.779338747140164045e+00</th>\n",
       "      <th>-1.429081038516362812e+00</th>\n",
       "      <th>2.685259494797771929e+00</th>\n",
       "      <th>9.533337453891782554e-01</th>\n",
       "      <th>-5.646716066842542014e-01</th>\n",
       "      <th>1.510000000000000000e+02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.515789</td>\n",
       "      <td>-0.799958</td>\n",
       "      <td>1.582195</td>\n",
       "      <td>-0.008126</td>\n",
       "      <td>0.414271</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.098582</td>\n",
       "      <td>-0.302917</td>\n",
       "      <td>-0.544602</td>\n",
       "      <td>-0.241896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241794</td>\n",
       "      <td>-0.937335</td>\n",
       "      <td>0.288955</td>\n",
       "      <td>-0.177624</td>\n",
       "      <td>0.084456</td>\n",
       "      <td>0.633965</td>\n",
       "      <td>1.052004</td>\n",
       "      <td>-0.113860</td>\n",
       "      <td>0.505908</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023454</td>\n",
       "      <td>0.048646</td>\n",
       "      <td>0.224159</td>\n",
       "      <td>0.655717</td>\n",
       "      <td>-0.176065</td>\n",
       "      <td>1.605403</td>\n",
       "      <td>1.638630</td>\n",
       "      <td>-1.240650</td>\n",
       "      <td>2.100396</td>\n",
       "      <td>-1.031570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483655</td>\n",
       "      <td>0.869513</td>\n",
       "      <td>0.881769</td>\n",
       "      <td>-0.958674</td>\n",
       "      <td>1.880679</td>\n",
       "      <td>0.608850</td>\n",
       "      <td>-0.057137</td>\n",
       "      <td>-0.950829</td>\n",
       "      <td>-0.594289</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.892292</td>\n",
       "      <td>-0.494714</td>\n",
       "      <td>-1.062153</td>\n",
       "      <td>0.736429</td>\n",
       "      <td>-0.118200</td>\n",
       "      <td>-1.078412</td>\n",
       "      <td>-0.454316</td>\n",
       "      <td>-0.378080</td>\n",
       "      <td>2.679422</td>\n",
       "      <td>-0.051751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385350</td>\n",
       "      <td>-0.021720</td>\n",
       "      <td>0.863478</td>\n",
       "      <td>0.256292</td>\n",
       "      <td>0.293780</td>\n",
       "      <td>0.216499</td>\n",
       "      <td>-0.637889</td>\n",
       "      <td>-1.179666</td>\n",
       "      <td>-1.112571</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.021634</td>\n",
       "      <td>-1.805761</td>\n",
       "      <td>0.082164</td>\n",
       "      <td>0.387965</td>\n",
       "      <td>-0.838219</td>\n",
       "      <td>1.596253</td>\n",
       "      <td>0.037945</td>\n",
       "      <td>-1.012175</td>\n",
       "      <td>1.632963</td>\n",
       "      <td>-0.533814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661239</td>\n",
       "      <td>0.329027</td>\n",
       "      <td>-0.757433</td>\n",
       "      <td>0.082726</td>\n",
       "      <td>0.267892</td>\n",
       "      <td>0.282614</td>\n",
       "      <td>-2.022049</td>\n",
       "      <td>-2.201643</td>\n",
       "      <td>0.786962</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.288486</td>\n",
       "      <td>-2.337547</td>\n",
       "      <td>-0.186132</td>\n",
       "      <td>-1.230419</td>\n",
       "      <td>-0.063607</td>\n",
       "      <td>-0.928346</td>\n",
       "      <td>-1.138335</td>\n",
       "      <td>-1.180762</td>\n",
       "      <td>0.530764</td>\n",
       "      <td>1.243531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585614</td>\n",
       "      <td>-0.317773</td>\n",
       "      <td>-0.637354</td>\n",
       "      <td>-1.450445</td>\n",
       "      <td>-1.656656</td>\n",
       "      <td>0.924630</td>\n",
       "      <td>-1.116395</td>\n",
       "      <td>-1.084778</td>\n",
       "      <td>1.107924</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2.237733528583032705e-01  2.407005121478057230e+00  \\\n",
       "0                 -0.515789                 -0.799958   \n",
       "1                  0.023454                  0.048646   \n",
       "2                  0.892292                 -0.494714   \n",
       "3                 -1.021634                 -1.805761   \n",
       "4                 -1.288486                 -2.337547   \n",
       "\n",
       "   -5.360732885543344484e-01  -1.336625915483726335e+00  \\\n",
       "0                   1.582195                  -0.008126   \n",
       "1                   0.224159                   0.655717   \n",
       "2                  -1.062153                   0.736429   \n",
       "3                   0.082164                   0.387965   \n",
       "4                  -0.186132                  -1.230419   \n",
       "\n",
       "   -9.794715446704517492e-02  1.549540399810333424e+00  \\\n",
       "0                   0.414271                  1.363709   \n",
       "1                  -0.176065                  1.605403   \n",
       "2                  -0.118200                 -1.078412   \n",
       "3                  -0.838219                  1.596253   \n",
       "4                  -0.063607                 -0.928346   \n",
       "\n",
       "   1.590890177396816707e+00  1.190101277089628207e+00  \\\n",
       "0                 -0.098582                 -0.302917   \n",
       "1                  1.638630                 -1.240650   \n",
       "2                 -0.454316                 -0.378080   \n",
       "3                  0.037945                 -1.012175   \n",
       "4                 -1.138335                 -1.180762   \n",
       "\n",
       "   -1.181935530900874776e+00  2.731035665376587929e+00  ...  \\\n",
       "0                  -0.544602                 -0.241896  ...   \n",
       "1                   2.100396                 -1.031570  ...   \n",
       "2                   2.679422                 -0.051751  ...   \n",
       "3                   1.632963                 -0.533814  ...   \n",
       "4                   0.530764                  1.243531  ...   \n",
       "\n",
       "   -1.157572374481870670e+00  -3.169548928408494337e-01  \\\n",
       "0                   0.241794                  -0.937335   \n",
       "1                   0.483655                   0.869513   \n",
       "2                   0.385350                  -0.021720   \n",
       "3                   0.661239                   0.329027   \n",
       "4                   0.585614                  -0.317773   \n",
       "\n",
       "   -1.041194344071040945e+00  -9.297458111228392719e-01  \\\n",
       "0                   0.288955                  -0.177624   \n",
       "1                   0.881769                  -0.958674   \n",
       "2                   0.863478                   0.256292   \n",
       "3                  -0.757433                   0.082726   \n",
       "4                  -0.637354                  -1.450445   \n",
       "\n",
       "   -1.779338747140164045e+00  -1.429081038516362812e+00  \\\n",
       "0                   0.084456                   0.633965   \n",
       "1                   1.880679                   0.608850   \n",
       "2                   0.293780                   0.216499   \n",
       "3                   0.267892                   0.282614   \n",
       "4                  -1.656656                   0.924630   \n",
       "\n",
       "   2.685259494797771929e+00  9.533337453891782554e-01  \\\n",
       "0                  1.052004                 -0.113860   \n",
       "1                 -0.057137                 -0.950829   \n",
       "2                 -0.637889                 -1.179666   \n",
       "3                 -2.022049                 -2.201643   \n",
       "4                 -1.116395                 -1.084778   \n",
       "\n",
       "   -5.646716066842542014e-01  1.510000000000000000e+02  \n",
       "0                   0.505908                      75.0  \n",
       "1                  -0.594289                     141.0  \n",
       "2                  -1.112571                     206.0  \n",
       "3                   0.786962                     135.0  \n",
       "4                   1.107924                      97.0  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('data_contamine.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0    6\n",
       "72.0     6\n",
       "90.0     5\n",
       "71.0     5\n",
       "178.0    5\n",
       "        ..\n",
       "40.0     1\n",
       "161.0    1\n",
       "45.0     1\n",
       "308.0    1\n",
       "317.0    1\n",
       "Name: 1.510000000000000000e+02, Length: 214, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['1.510000000000000000e+02'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 2\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Les variables explicatives sont-elles centrées ? Normalisées ? Qu’en est-il de la variable à expliquer ? Tracer un scatter plot de la base de données avec 4 covariables prises au hasard et la variable à expliquer (un scatterplot regroupe les graphes de chacune des variables en fonction de chacune des autres). Commenter les graphiques obtenus. (1.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 3\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Echantillon d’apprentissage et de test. Créer 2 échantillons : un pour apprendre le modèle Xtrain, un pour tester le modèle Xtest. On mettra 25% de la base dans l’échantillon ’test’. Donner les tailles de chacun des 2 échantillons. On notera que le nouvel échantillon de covariables Xtrain n’est pas normalisé. Dans la suite, on fera donc bien attention à inclure l’intercept dans nos régressions. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 4\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Donner la matrice de covariance calculée sur Xtrain. Tracer le graphe de la décroissance des valeurs propres de la matrice de covariance (ou de corrélation). Expliquer pourquoi il est légitime de ne garder que les premières variables de l’ACP. On gardera 20 variables dans la suite. (1.5 point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 5\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Suivant les observations de la question (Q4), appliquer la méthode de \"PCA before OLS\" qui consiste à appliquer OLS avec Y et XtrainVp1:20q, où Vp1:20q contient les vecteurs propres (associés aux 20 plus grandes valeurs propres) de la matrice de covariance. Faire une régression linéaire (avec intercept), puis tracer les valeurs des coefficients (hors intercept). Sur un autre graphique, faire de même avec la méthode des moindres carrés classique. (1 point)Les variables explicatives sont-elles centrées ? Normalisées ? Qu’en est-il de la variable à expliquer ? Tracer un scatter plot de la base de données avec 4 covariables prises au hasard et la variable à expliquer (un scatterplot regroupe les graphes de chacune des variables en fonction de chacune des autres). Commenter les graphiques obtenus. (1.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 6\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Donner les valeurs des intercepts pour les 2 régressions précédentes. Donner la valeur moyenne de la variable Y (sur le train set). Les intercepts des 2 questions sont-ils égaux ? Commenter. Uniquement pour cette question, centrer et réduire les variables après ACP (de petite dimension). Faire une régression avec ces variables et vérifier que l’intercept est bien égal à la moyenne de Y sur le train. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 7\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pour les 2 méthodes (OLS et PCA before OLS) : Tracer les résidus de la prédiction sur l’échantillon test. Tracer leur densité (on pourra par exemple utiliser un histogramme). Calculer le coefficient de détermination sur l’échantillon test. Calculer le risque de prédiction sur l’échantillon test. (1.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 8\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Coder la méthode de Forward variable sélection. On pourra utiliser la statistique du test de nullitédu coefficient (comme vu en cours). Pour l’instant, on ne met pas de critère d’arrêt sur la méthode, c’est-à-dire que l’on ajoute une variable à chaque étape jusqu’à retrouver la totalité des variables.Sachant que le jeu de données initiales ne contenait que les variables [22, 82, 23, 132, 154, 79, 115, 73, 122, 13], combien Forward en a-t-il retrouvé ? (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 9\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Appliquer OLS sur les variables sélectionnées. Donner le risque de prédiction obtenu sur l’échantillon test et le comparer à ceux de OLS et PCA before OLS. (1.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 10\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Afin de préparer la validation croisée, séparer l’échantillon train en 5 parties (appelées ”folds”) de façon aléatoire. On affichera les numéros d’échantillon sélectionnés dans chaque fold. (2 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 11\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Appliquer la méthode de la régression Ridge. Pour le choix du paramètre de régularisation, on fera une validation croisée sur les ”folds” définis lors de la question précédente. A tour de rôle chacun des ”folds” servira à calculer le risque de prédiction alors que les autres seront utilisés pour estimer le modèle. On moyennera ensuite les 5 risques de prédictions. On donnera la courbe du risque de validation croisée en fonction du paramètre de régularisation (on veillera à bien choisir l’espace de définition pour le graphe). Donner le paramètre de régularisation optimal et la valeur du risque sur le test. (1.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 12\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A l’aide de la fonction lassoCV de sklearn, choisir le paramètre de régularisation du LASSO. Donner le risque de prédiction associé. (1.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 13\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Donner les variables selectionées par le Lasso. Combien y en a-t-il ? Appliquer la méthode OLS aux variables sélectionnées. Cette méthode est appelé Least-Square LASSO. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Question 14\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Les variables initiales du jeu de données sont [22, 82, 23, 132, 154, 79, 115, 73, 122, 13]. Combien le Lasso en a-t-il retrouvé ? (1 point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
